{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Alvaro/Desktop/projects/phage/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqFeature import FeatureLocation\n",
    "from Bio.Seq import UndefinedSequenceError\n",
    "from collections import defaultdict\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input is a genbank file, which is the only thing to be parsed. The output from engineer features is assigned a class staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(genbank_file):\n",
    "    # Lists to hold data\n",
    "    ids = []\n",
    "    genome_lengths = []\n",
    "    gc_contents = []\n",
    "    sequences = []\n",
    "    reverse_complements = []\n",
    "    cds_numbers = []\n",
    "    positive_strands = []\n",
    "    negative_strands = []\n",
    "    coding_capacities = []\n",
    "    molecule_types = []\n",
    "    topologies = []\n",
    "    trna_counts = []\n",
    "\n",
    "    \n",
    "    # Read the GenBank file\n",
    "    for record in SeqIO.parse(genbank_file, \"genbank\"):\n",
    "        try:\n",
    "            # Attempt to access the sequence, which may raise UndefinedSequenceError\n",
    "            sequence = str(record.seq)\n",
    "            # print(record.id)\n",
    "        except UndefinedSequenceError:\n",
    "            # print(f\"Skipping record {record.id} as sequence is undefined.\")\n",
    "            continue  # Skip this record\n",
    "\n",
    "        # Calculate genome length and GC content\n",
    "        total_length = len(sequence)\n",
    "        gc_content = round((sequence.count('C') + sequence.count('G')) / total_length * 100, 3)\n",
    "\n",
    "        # Initialize counters\n",
    "        plus = 0\n",
    "        minus = 0\n",
    "        coding_count = 0\n",
    "        trna_count = 0\n",
    "        seen = set()  # Store seen barcodes\n",
    "\n",
    "        for feature in record.features:\n",
    "            start = feature.location.start\n",
    "            end = feature.location.end\n",
    "            length = len(FeatureLocation(start, end))\n",
    "            barcode = f\"{start}_{end}_{length}\"\n",
    "\n",
    "            if feature.type != 'source' and barcode not in seen:\n",
    "                coding_count += length\n",
    "                seen.add(barcode)\n",
    "\n",
    "            if feature.type == 'CDS':\n",
    "                if feature.location.strand == 1:\n",
    "                    plus += 1\n",
    "                elif feature.location.strand == -1:\n",
    "                    minus += 1\n",
    "            elif feature.type == 'tRNA':\n",
    "                trna_count += 1\n",
    "\n",
    "        \n",
    "        # Calculate total number of CDS\n",
    "        total_CDS = plus + minus\n",
    "\n",
    "        # Calculate strand usage as a percentage\n",
    "        per_plus = round((plus / total_CDS) * 100, 2) if total_CDS != 0 else 0\n",
    "        per_minus = round((minus / total_CDS) * 100, 2) if total_CDS != 0 else 0\n",
    "\n",
    "        # Calculate coding capacity as a percentage\n",
    "        coding_capacity = (coding_count / total_length) * 100\n",
    "\n",
    "        # Extract molecule_type and topology\n",
    "        molecule_type = record.annotations.get('molecule_type', 'N/A')\n",
    "        topology = record.annotations.get('topology', 'N/A')\n",
    "\n",
    "        # Append data to lists\n",
    "        ids.append(record.id)\n",
    "        genome_lengths.append(total_length)\n",
    "        gc_contents.append(gc_content)\n",
    "        sequences.append(sequence)\n",
    "        reverse_complements.append(str(sequence[::-1]))\n",
    "        cds_numbers.append(total_CDS)\n",
    "        positive_strands.append(per_plus)\n",
    "        negative_strands.append(per_minus)\n",
    "        coding_capacities.append(coding_capacity)\n",
    "        molecule_types.append(molecule_type)\n",
    "        topologies.append(topology)\n",
    "        trna_counts.append(trna_count)\n",
    "    \n",
    "    print(\"Processing the entries...\")\n",
    "    # Convert lists to pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'genome_length': genome_lengths,\n",
    "        'gc_%': gc_contents,\n",
    "        'sequence': sequences,\n",
    "        'reverse_complement': reverse_complements,\n",
    "        'cds_number': cds_numbers,\n",
    "        'positive_strand_%': positive_strands,\n",
    "        'negative_strand_%': negative_strands,\n",
    "        'coding_capacity': coding_capacities,\n",
    "        'molecule_type': molecule_types,\n",
    "        'topology': topologies,\n",
    "        'trna_count': trna_counts\n",
    "    })\n",
    "\n",
    "\n",
    "    df['id'] = df['id'].str[:-2]\n",
    "\n",
    "    # Check for unexpected molecule types\n",
    "    expected_molecule_types = ['ss-DNA', 'DNA', 'RNA', 'ss-RNA']\n",
    "\n",
    "    # Check and correct 'cRNA' entries\n",
    "    cRNA_entries = df[df['molecule_type'] == 'cRNA']\n",
    "    if not cRNA_entries.empty:\n",
    "        for entry_id in cRNA_entries['id']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cRNA'. Changing it to 'RNA'.\")\n",
    "        df.loc[df['molecule_type'] == 'cRNA', 'molecule_type'] = 'RNA'\n",
    "\n",
    "    # Check and correct 'cDNA' entries\n",
    "    cDNA_entries = df[df['molecule_type'] == 'cDNA']\n",
    "    if not cDNA_entries.empty:\n",
    "        for entry_id in cDNA_entries['id']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cDNA'. Changing it to 'DNA'.\")\n",
    "        df.loc[df['molecule_type'] == 'cDNA', 'molecule_type'] = 'DNA'\n",
    "\n",
    "    unexpected_types = set(df['molecule_type']) - set(expected_molecule_types)\n",
    "\n",
    "    if unexpected_types:\n",
    "        for utype in unexpected_types:\n",
    "            # Get ids of entries with the unexpected molecule type\n",
    "            ids_to_exclude = df[df['molecule_type'] == utype]['id'].tolist()\n",
    "            for entry_id in ids_to_exclude:\n",
    "                print(f\"Warning: Entry with id '{entry_id}' has unrecognized molecule type '{utype}'. It will not be considered.\")\n",
    "            df = df[df['molecule_type'] != utype]\n",
    "            \n",
    "    df = pd.get_dummies(df, columns=['molecule_type'])\n",
    "\n",
    "    expected_columns = ['jumbophage', 'molecule_type_ss-DNA', 'molecule_type_DNA', 'molecule_type_RNA', 'molecule_type_ss-RNA']\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Filling with zeros\n",
    "        df[col] = df[col].astype(bool)  # Convert to boolean\n",
    "\n",
    "    df['jumbophage'] = df['genome_length'].apply(lambda x: x >= 200000)\n",
    "    df['jumbophage'] = df['jumbophage'].astype(int)  # Convert True/False to 1/0\n",
    "    df = pd.get_dummies(df, columns=['topology'])\n",
    "    return df\n",
    "\n",
    "def staining_feature(staining_df, features_df):\n",
    "    stain = pd.read_csv(staining_df, index_col = 0)\n",
    "    stain = stain[['Accession', 'staining']]\n",
    "    stain = stain.rename(columns={'Accession': 'id'})\n",
    "\n",
    "    features_df = pd.merge(features_df, stain, on='id', how='left')\n",
    "    features_df = features_df[['id', 'staining', 'genome_length', 'jumbophage', 'gc_%', 'trna_count','cds_number', 'coding_capacity',\n",
    "                               'positive_strand_%','negative_strand_%', 'molecule_type_ss-DNA', 'molecule_type_DNA', 'molecule_type_RNA', 'molecule_type_ss-RNA',\n",
    "                               'topology_circular', 'topology_linear']]\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Load a trained model from a given path.\")\n",
    "    optional = parser._action_groups.pop()\n",
    "    required = parser.add_argument_group('required arguments')\n",
    "\n",
    "    parser.add_argument(\"-g\", \"--genbank\", type=str, required=True,\n",
    "                        help=\"Path to genbank file of the entry.\")\n",
    "    optional.add_argument(\"-s\",\"--staining\", dest=\"staining\", action='store', \n",
    "                          default='data/interim/gram_staining/staining_assignation.csv', \n",
    "                          help=\"Path to csv file with a customised gram staining class assignation for every entry.\")\n",
    "    optional.add_argument(\"-o\",\"--output_direcotry\", dest=\"output\", action='store', \n",
    "                          default='data/processed/model_data_pharokka.csv', help=\"Output path (default: data/processed/model_data_pharokka.csv).\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # The genbank file input should be the output of pharokka \n",
    "\n",
    "    print(\"Reading the genbank file...\")\n",
    "    features_df = engineer_features(args.genbank)\n",
    "\n",
    "    features_df = staining_feature(args.staining, features_df)\n",
    "\n",
    "    features_df.to_csv(args.output, index = False)\n",
    "    \n",
    "    print(f\"Processed data has been stored in {args.output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a folder containing the pharokka output for a set of phages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(folder):\n",
    "    # Lists to hold data\n",
    "    ids = []\n",
    "    genome_lengths = []\n",
    "    gc_contents = []\n",
    "    sequences = []\n",
    "    reverse_complements = []\n",
    "    cds_numbers = []\n",
    "    positive_strands = []\n",
    "    negative_strands = []\n",
    "    coding_capacities = []\n",
    "    molecule_types = []\n",
    "    topologies = []\n",
    "    trna_counts = []\n",
    "\n",
    "    genbank_file = f'{folder}/pharokka.gbk'\n",
    "\n",
    "    # Read the GenBank file\n",
    "    for record in SeqIO.parse(genbank_file, \"genbank\"):\n",
    "        try:\n",
    "            # Attempt to access the sequence, which may raise UndefinedSequenceError\n",
    "            sequence = str(record.seq)\n",
    "            # print(record.id)\n",
    "        except UndefinedSequenceError:\n",
    "            # print(f\"Skipping record {record.id} as sequence is undefined.\")\n",
    "            continue  # Skip this record\n",
    "\n",
    "        # Calculate genome length and GC content\n",
    "        total_length = len(sequence)\n",
    "        gc_content = round((sequence.count('C') + sequence.count('G')) / total_length * 100, 3)\n",
    "\n",
    "        # Initialize counters\n",
    "        plus = 0\n",
    "        minus = 0\n",
    "        coding_count = 0\n",
    "        trna_count = 0\n",
    "        seen = set()  # Store seen barcodes\n",
    "\n",
    "        for feature in record.features:\n",
    "            start = feature.location.start\n",
    "            end = feature.location.end\n",
    "            length = len(FeatureLocation(start, end))\n",
    "            barcode = f\"{start}_{end}_{length}\"\n",
    "\n",
    "            if feature.type != 'source' and barcode not in seen:\n",
    "                coding_count += length\n",
    "                seen.add(barcode)\n",
    "\n",
    "            if feature.type == 'CDS':\n",
    "                if feature.location.strand == 1:\n",
    "                    plus += 1\n",
    "                elif feature.location.strand == -1:\n",
    "                    minus += 1\n",
    "            elif feature.type == 'tRNA':\n",
    "                trna_count += 1\n",
    "\n",
    "        \n",
    "        # Calculate total number of CDS\n",
    "        total_CDS = plus + minus\n",
    "\n",
    "        # Calculate strand usage as a percentage\n",
    "        per_plus = round((plus / total_CDS) * 100, 2) if total_CDS != 0 else 0\n",
    "        per_minus = round((minus / total_CDS) * 100, 2) if total_CDS != 0 else 0\n",
    "\n",
    "        # Calculate coding capacity as a percentage\n",
    "        coding_capacity = (coding_count / total_length) * 100\n",
    "\n",
    "        # Extract molecule_type and topology\n",
    "        molecule_type = record.annotations.get('molecule_type', 'N/A')\n",
    "        topology = record.annotations.get('topology', 'N/A')\n",
    "\n",
    "        # Append data to lists\n",
    "        ids.append(record.id)\n",
    "        genome_lengths.append(total_length)\n",
    "        gc_contents.append(gc_content)\n",
    "        sequences.append(sequence)\n",
    "        reverse_complements.append(str(sequence[::-1]))\n",
    "        cds_numbers.append(total_CDS)\n",
    "        positive_strands.append(per_plus)\n",
    "        negative_strands.append(per_minus)\n",
    "        coding_capacities.append(coding_capacity)\n",
    "        molecule_types.append(molecule_type)\n",
    "        topologies.append(topology)\n",
    "        trna_counts.append(trna_count)\n",
    "    \n",
    "    print(\"Processing the entries...\")\n",
    "    # Convert lists to pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'id_inphared': ids,\n",
    "        'genome_length_inphared': genome_lengths,\n",
    "        'gc_%_inphared': gc_contents,\n",
    "        'sequence_inphared': sequences,\n",
    "        'reverse_complement_inphared': reverse_complements,\n",
    "        'cds_number_inphared': cds_numbers,\n",
    "        'positive_strand_%_inphared': positive_strands,\n",
    "        'negative_strand_%_inphared': negative_strands,\n",
    "        'coding_capacity_inphared': coding_capacities,\n",
    "        'molecule_type_inphared': molecule_types,\n",
    "        'topology_inphared': topologies\n",
    "    })\n",
    "\n",
    "\n",
    "    df['id_inphared'] = df['id_inphared'].str[:-2]\n",
    "\n",
    "    # Check for unexpected molecule types\n",
    "    expected_molecule_types = ['ss-DNA', 'DNA', 'RNA', 'ss-RNA']\n",
    "\n",
    "    # Check and correct 'cRNA' entries\n",
    "    cRNA_entries = df[df['molecule_type_inphared'] == 'cRNA']\n",
    "    if not cRNA_entries.empty:\n",
    "        for entry_id in cRNA_entries['id_inphared']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cRNA'. Changing it to 'RNA'.\")\n",
    "        df.loc[df['molecule_type_inphared'] == 'cRNA', 'molecule_type_inphared'] = 'RNA'\n",
    "\n",
    "    # Check and correct 'cDNA' entries\n",
    "    cDNA_entries = df[df['molecule_type_inphared'] == 'cDNA']\n",
    "    if not cDNA_entries.empty:\n",
    "        for entry_id in cDNA_entries['id_inphared']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cDNA'. Changing it to 'DNA'.\")\n",
    "        df.loc[df['molecule_type_inphared'] == 'cDNA', 'molecule_type_inphared'] = 'DNA'\n",
    "\n",
    "    unexpected_types = set(df['molecule_type_inphared']) - set(expected_molecule_types)\n",
    "\n",
    "    if unexpected_types:\n",
    "        for utype in unexpected_types:\n",
    "            # Get ids of entries with the unexpected molecule type\n",
    "            ids_to_exclude = df[df['molecule_type_inphared'] == utype]['id'].tolist()\n",
    "            for entry_id in ids_to_exclude:\n",
    "                print(f\"Warning: Entry with id '{entry_id}' has unrecognized molecule type '{utype}'. It will not be considered.\")\n",
    "            df = df[df['molecule_type'] != utype]\n",
    "            \n",
    "    df = pd.get_dummies(df, columns=['molecule_type_inphared'])\n",
    "    df = pd.get_dummies(df, columns=['topology_inphared'])\n",
    "    expected_columns = ['jumbophage_inphared', 'topology_linear_inphared','topology_circular_inphared',\n",
    "    'molecule_inphared_type_ss-DNA', 'molecule_inphared_type_DNA', 'molecule_inphared_type_RNA', 'molecule_inphared_type_ss-RNA']\n",
    "    \n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Filling with zeros\n",
    "        df[col] = df[col].astype(bool)  # Convert to boolean\n",
    "\n",
    "    df['jumbophage_inphared'] = df['genome_length_inphared'].apply(lambda x: x >= 200000)\n",
    "    df['jumbophage_inphared'] = df['jumbophage_inphared'].astype(int)  # Convert True/False to 1/0\n",
    "    \n",
    "    df['id_inphared'] = df['id_inphared'].str.slice(0,8)\n",
    "\n",
    "\n",
    "    df_length_gc_cds_density = pd.read_csv(f\"{folder}pharokka_length_gc_cds_density.tsv\", sep=\"\\t\")\n",
    "    df_length_gc_cds_density['contig'] = df_length_gc_cds_density['contig'].str.slice(0,8)\n",
    "    df_length_gc_cds_density\n",
    "\n",
    "    df = pd.merge(df, df_length_gc_cds_density, left_on='id_inphared', right_on='contig', how='outer')\n",
    "    del(df_length_gc_cds_density)\n",
    "\n",
    "    df_cds = pd.read_csv(f\"{folder}pharokka_cds_functions.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    # Define a dictionary of replacements\n",
    "    replacements = {\n",
    "        \"DNA, RNA and nucleotide metabolism\":\"nucleotide_metabolism\",\n",
    "        \"head and packaging\": \"head_packaging\",\n",
    "        \"moron, auxiliary metabolic gene and host takeover\": \"host_takeover\",\n",
    "        \"transcription regulation\": \"transcription\",\n",
    "        \"unknown function\": \"unkown_function\"\n",
    "    }\n",
    "\n",
    "    # Replace the values using the dictionary\n",
    "    df_cds['Description'] = df_cds['Description'].replace(replacements)\n",
    "\n",
    "    df_cds = df_cds.pivot(index='contig', columns='Description', values='Count').reset_index()\n",
    "    df_cds['contig'] = df_cds['contig'].str.slice(0,8)\n",
    "\n",
    "    df = pd.merge(df, df_cds, left_on='id_inphared', right_on='contig', how='outer')\n",
    "    del(df_cds)\n",
    "\n",
    "    # Specify dtype to avoid importing issues \n",
    "    dtype_spec = {\n",
    "        'vfdb_species': 'str',\n",
    "        'CARD_eVal': 'float',  # Float because it's numeric but can contain NaN\n",
    "        'CARD_species': 'str',\n",
    "        'ARO_Accession': 'str',\n",
    "        'CARD_short_name': 'str',\n",
    "        'Protein_Accession': 'str',\n",
    "        'DNA_Accession': 'str',\n",
    "        'AMR_Gene_Family': 'str',\n",
    "        'Drug_Class': 'str'\n",
    "    }\n",
    "\n",
    "    df_frame = pd.read_csv(f\"{folder}pharokka_cds_final_merged_output.tsv\", sep=\"\\t\", dtype=dtype_spec, low_memory=False)\n",
    "\n",
    "    frame_counts = df_frame.groupby('contig')['frame'].value_counts().unstack(fill_value=0)\n",
    "    frame_counts.columns = ['frame_negative', 'frame_positive']\n",
    "    frame_counts = frame_counts.rename_axis(None, axis=1).reset_index()\n",
    "    frame_counts['contig'] = frame_counts['contig'].str.slice(0,8)\n",
    "    df = pd.merge(df, frame_counts, left_on='id_inphared', right_on='contig', how='outer')\n",
    "\n",
    "    df = df.rename(columns={'id_inphared': 'id'})\n",
    "\n",
    "    # List of columns to be ignored in the duplicate check\n",
    "    ignore_columns = {\n",
    "        'CARD_AMR_Genes', 'CDS', 'CRISPRs', 'VFDB_Virulence_Factors', 'connector',\n",
    "        'head_packaging', 'host_takeover', 'integration and excision', 'lysis',\n",
    "        'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
    "        'transcription', 'unkown_function'\n",
    "    }\n",
    "\n",
    "    # # Function to check for repeated values excluding 0 and 1 and certain columns\n",
    "    # def find_repeated_values(row):\n",
    "    #     # Use defaultdict to associate multiple columns with the same value\n",
    "    #     repeated_columns = defaultdict(list)\n",
    "    #     # Use items() instead of iteritems()\n",
    "    #     for col, value in row.items():\n",
    "    #         if col in ignore_columns:  # Skip the iteration for specified columns\n",
    "    #             continue\n",
    "    #         if (value in [0, 1]) or pd.isnull(value):  # Skip values of 0, 1, or NaN\n",
    "    #             continue\n",
    "    #         if row[row == value].count() > 1:  # If value count in row is more than one, it's a duplicate\n",
    "    #             repeated_columns[value].append(col)\n",
    "    #     return repeated_columns\n",
    "\n",
    "    # # Ensure row is a Series before passing to find_repeated_values\n",
    "    # for index, row in df.iterrows():\n",
    "    #     repeated_values_dict = find_repeated_values(row)\n",
    "    #     if repeated_values_dict:  # If there's any repeated value\n",
    "    #         warning_message = f\"Entry {row['id']} shows repeated values in \"\n",
    "    #         # Create a combined message for duplicate columns sharing the same value\n",
    "    #         message_parts = []\n",
    "    #         for val, cols in repeated_values_dict.items():\n",
    "    #             if len(cols) > 1:  # Only add to message if there are indeed duplicates\n",
    "    #                 combined_cols = ' and '.join(cols)  # Combine column names\n",
    "    #                 message_parts.append(f\"columns {combined_cols} (value {val})\")\n",
    "    #         warning_message += ', '.join(message_parts)\n",
    "    #         print(warning_message)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staining_feature(staining_df, features_df):\n",
    "    stain = pd.read_csv(staining_df, index_col = 0)\n",
    "    stain = stain[['Accession', 'staining']]\n",
    "    stain = stain.rename(columns={'Accession': 'id'})\n",
    "\n",
    "    features_df = pd.merge(features_df, stain, on='id', how='left')\n",
    "    features_df = features_df[['id', 'staining', 'genome_length_inphared', 'gc_%_inphared',\n",
    "        'cds_number_inphared', 'positive_strand_%_inphared',\n",
    "        'negative_strand_%_inphared', 'coding_capacity_inphared',\n",
    "        'molecule_type_inphared_DNA', 'topology_inphared_linear',\n",
    "        'jumbophage_inphared', 'topology_linear_inphared',\n",
    "        'topology_circular_inphared', 'molecule_inphared_type_ss-DNA',\n",
    "        'molecule_inphared_type_DNA', 'molecule_inphared_type_RNA',\n",
    "        'molecule_inphared_type_ss-RNA', 'length', 'gc_perc',\n",
    "        'transl_table', 'cds_coding_density', 'CARD_AMR_Genes',\n",
    "        'CDS', 'CRISPRs', 'VFDB_Virulence_Factors', 'connector',\n",
    "        'head_packaging', 'host_takeover', 'integration and excision', 'lysis',\n",
    "        'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
    "        'transcription', 'unkown_function', 'frame_negative',\n",
    "        'frame_positive', 'sequence_inphared', 'reverse_complement_inphared']]\n",
    "\n",
    "\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the entries...\n"
     ]
    }
   ],
   "source": [
    "code = \"MZ079855__Klebsiella_phage_vB_Kpn_3\" \n",
    "code = \"MW006474__Salmonella_phage_GEC_vB_B1\"\n",
    "entry = f\"../data/interim/pharokka/tmp_pharokka/{code}.fna_pharokka/\"\n",
    "entry = \"../data/interim/pharokka/output_50/\"\n",
    "df = engineer_features(entry)\n",
    "stain = \"../data/interim/gram_staining/staining_assignation.csv\"\n",
    "df = staining_feature(stain,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Process raw data into features to train a model.\")\n",
    "    optional = parser._action_groups.pop()\n",
    "    required = parser.add_argument_group('required arguments')\n",
    "    parser.add_argument(\"-d\", \"--data\", type=str, required=True,\n",
    "                        help=\"Path to the data. Accepted inputs are FASTA files for Pharokka inputs or a directory path to an already processed Pharokka output.\\\n",
    "                            If the input is a FASTA file, the Pharokka output will be stored locally.\")\n",
    "    optional.add_argument(\"-s\",\"--staining\", dest=\"staining\", action='store', \n",
    "                          default='data/interim/gram_staining/staining_assignation.csv', \n",
    "                          help=\"Path to csv file with a customised gram staining class assignation for every entry.\")\n",
    "    optional.add_argument(\"-o\",\"--output_directory\", dest=\"output\", action='store', \n",
    "                          default='data/processed/model_data_pharokka.csv', help=\"Output path (default: data/processed/model_data_pharokka.csv).\")\n",
    "    optional.add_argument(\"-p\",\"--pharokka_directory\", dest=\"pharokka\", action='store', \n",
    "                          default=\"/mnt/c/Users/Alvaro/Desktop/pharokka_output/\", help=\"Path where pharokka output will be stored (default: /mnt/c/Users/Alvaro/Desktop/pharokka_output/).\")\n",
    "    optional.add_argument(\"-b\",\"--database_directory\", dest=\"database\", action='store', \n",
    "                          default=\"/mnt/c/Users/Alvaro/Desktop/pharokka_database/\", help=\"Path to the Pharokka database (default./mnt/c/Users/Alvaro/Desktop/pharokka_database/).\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    '''\n",
    "    Possible inputs:\n",
    "    - Pharokka output\n",
    "    - Fasta file on which to build pharokka output\n",
    "\n",
    "    This output will be the input for the engineer features and staining feature, and its\n",
    "    output is stored in args.output. This output is used by train_model for training\n",
    "    '''\n",
    "    fasta_extensions = [\"fasta\", \"fas\", \"fa\", \"fna\", \"ffn\", \"faa\", \"mpfa\", \"frn\"]\n",
    "\n",
    "    def unix_call(command, environment=None):\n",
    "        if environment:  # If the environment is specified, prepend with 'conda run -n env_name'\n",
    "            command = f\"conda run -n {environment} {command}\"\n",
    "        subprocess.run(command, shell=True, check=True)  \n",
    "\n",
    "    def process_fasta(file_path, output_dir, database_dir):\n",
    "        # Create the output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Processing FASTA file: {file_path}\")\n",
    "\n",
    "        # Run Pharokka using the pharokkaENV environment\n",
    "        unix_call(f'pharokka.py -i {file_path} -o {output_dir} -f -m -t 16 -d {database_dir}', environment='pharokkaENV')\n",
    "\n",
    "        \n",
    "    # Check if the input data path is a directory or a file\n",
    "    if os.path.isdir(args.data):\n",
    "        # The input is a directory; process all relevant files within\n",
    "        print(f\"Processing Pharokka output in directory: {args.data}\")\n",
    "        model_data = engineer_features(args.data)\n",
    "\n",
    "    elif os.path.isfile(args.data):\n",
    "        # The input is a file; check if it's a FASTA file\n",
    "        file_ext = os.path.splitext(args.data)[1][1:].lower()\n",
    "        if file_ext in fasta_extensions:\n",
    "            process_fasta(args.data, args.pharokka, args.database) \n",
    "\n",
    "            # The input is a directory; process all relevant files within\n",
    "            print(f\"Processing Pharokka output in directory: {args.pharokka}\")\n",
    "            model_data = engineer_features(args.pharokka)\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_ext}. Supported FASTA formats are: {', '.join(fasta_extensions)}\")\n",
    "            exit(1)\n",
    "\n",
    "\n",
    "    model_data = staining_feature(args.staining, model_data)\n",
    "\n",
    "    model_data.to_csv(args.output, index = False)\n",
    "    \n",
    "    print(f\"Processed data has been stored in {args.output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_strand_%_inphared</th>\n",
       "      <th>frame_positive</th>\n",
       "      <th>positive_strand_%_inphared</th>\n",
       "      <th>frame_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>66</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative_strand_%_inphared  frame_positive  positive_strand_%_inphared  \\\n",
       "2                        66.0              66                        34.0   \n",
       "\n",
       "   frame_negative  \n",
       "2              34  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weird issue: Entry AY129332 shows repeated values in columns positive_strand_%_inphared and frame_negative (value 34.0), columns negative_strand_%_inphared and frame_positive (value 66.0)\n",
    "\n",
    "df[df[\"id_inphared\"] == \"AY129332\"][[\"negative_strand_%_inphared\", \"frame_positive\", \"positive_strand_%_inphared\", \"frame_negative\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a folder which contains individual folders which contains the output for each phage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the problems\n",
    "def engineer_features(folder):\n",
    "    # Read data from the TSV file\n",
    "    df = pd.read_csv(f'{folder}/pharokka_top_hits_mash_inphared.tsv', sep='\\t')\n",
    "\n",
    "    # Select only the columns you need\n",
    "    selected_columns = [\n",
    "        'Accession', 'contig','Genome_Length_(bp)', 'molGC_(%)', 'Molecule',\n",
    "        'Number_CDS', 'Positive_Strand_(%)', 'Negative_Strand_(%)',\n",
    "        'Coding_Capacity_(%)', 'tRNAs', 'Host', \n",
    "        'Isolation_Host_(beware_inconsistent_and_nonsense_values)'\n",
    "    ]\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    # Rename columns to match your previous DataFrame structure\n",
    "    df = df.rename(columns={\n",
    "        'Accession': 'id_inphared',\n",
    "        'contig': 'contig_inphared',\n",
    "        'Genome_Length_(bp)': 'genome_length_inphared',\n",
    "        'molGC_(%)': 'gc_%_inphared',\n",
    "        'Molecule': 'molecule_inphared_type',\n",
    "        'Number_CDS': 'cds_number_inphared',\n",
    "        'Positive_Strand_(%)': 'positive_strand_%_inphared',\n",
    "        'Negative_Strand_(%)': 'negative_strand_%_inphared',\n",
    "        'Coding_Capacity_(%)': 'coding_capacity_inphared',\n",
    "        'tRNAs': 'tRNAs_inphared',\n",
    "        'Host': 'host_inphared',\n",
    "        'Isolation_Host_(beware_inconsistent_and_nonsense_values)': 'isolation_host_inphared'\n",
    "    })\n",
    "\n",
    "    # Initialize lists for storing data\n",
    "    ids = []\n",
    "    topologies = []\n",
    "    sequences = []\n",
    "\n",
    "    # Read the GenBank file for topology and sequences\n",
    "    genbank_file = f'{folder}/pharokka.gbk'\n",
    "    for record in SeqIO.parse(genbank_file, \"genbank\"):\n",
    "        ids.append(record.id)    \n",
    "        topologies.append(record.annotations.get('topology', 'N/A'))\n",
    "        sequences.append(str(record.seq))\n",
    "\n",
    "\n",
    "    # These lines use the \"contig\" column of inphared tsv when the \"Accession\" is wrong (does not match the one in Genbank file?)\n",
    "    genbank_id = ids[0] if ids else None\n",
    "\n",
    "    # Update Accession value based on the logic described\n",
    "    for index, row in df.iterrows():\n",
    "        if row['id_inphared'] != genbank_id and row['contig_inphared'] == genbank_id:\n",
    "            print(f\"Updating Accession for folder {folder}: from {row['id_inphared']} to {genbank_id}\")\n",
    "            df.at[index, 'id_inphared'] = genbank_id\n",
    "\n",
    "\n",
    "\n",
    "    # Create DataFrames from the topologies and sequences\n",
    "    topology_df = pd.DataFrame({'id_inphared': ids, 'topology': topologies})\n",
    "    sequence_df = pd.DataFrame({'id_inphared': ids, 'sequence': sequences})\n",
    "\n",
    "    # Merge the TSV data with the GenBank topology and sequence data\n",
    "    df = pd.merge(df, topology_df, on='id_inphared', how='left')\n",
    "    df = pd.merge(df, sequence_df, on='id_inphared', how='left')\n",
    "    del(topology_df)\n",
    "    del(sequence_df)\n",
    "\n",
    "    # Check for unexpected molecule types\n",
    "    expected_molecule_types = ['ss-DNA', 'DNA', 'RNA', 'ss-RNA']\n",
    "\n",
    "    # Check and correct 'cRNA' entries\n",
    "    cRNA_entries = df[df['molecule_inphared_type'] == 'cRNA']\n",
    "    if not cRNA_entries.empty:\n",
    "        for entry_id in cRNA_entries['id_inphared']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cRNA'. Changing it to 'RNA'.\")\n",
    "        df.loc[df['molecule_inphared_type'] == 'cRNA', 'molecule_inphared_type'] = 'RNA'\n",
    "\n",
    "    # Check and correct 'cDNA' entries\n",
    "    cDNA_entries = df[df['molecule_inphared_type'] == 'cDNA']\n",
    "    if not cDNA_entries.empty:\n",
    "        for entry_id in cDNA_entries['id_inphared']:\n",
    "            print(f\"Info: Entry with id '{entry_id}' has molecule type 'cDNA'. Changing it to 'DNA'.\")\n",
    "        df.loc[df['molecule_inphared_type'] == 'cDNA', 'molecule_inphared_type'] = 'DNA'\n",
    "\n",
    "    unexpected_types = set(df['molecule_inphared_type']) - set(expected_molecule_types)\n",
    "\n",
    "    if unexpected_types:\n",
    "        for utype in unexpected_types:\n",
    "            # Get ids of entries with the unexpected molecule type\n",
    "            ids_to_exclude = df[df['molecule_inphared_type'] == utype]['id_inphared'].tolist()\n",
    "            for entry_id in ids_to_exclude:\n",
    "                print(f\"Warning: Entry with id '{entry_id}' has unrecognized molecule type '{utype}'. It will not be considered.\")\n",
    "            df = df[df['molecule_inphared_type'] != utype]\n",
    "            \n",
    "    df = pd.get_dummies(df, columns=['molecule_inphared_type'])\n",
    "    df = pd.get_dummies(df, columns=['topology'])\n",
    "    expected_columns = ['jumbophage_inphared', 'topology_linear','topology_circular',\n",
    "    'molecule_inphared_type_ss-DNA', 'molecule_inphared_type_DNA', 'molecule_inphared_type_RNA', 'molecule_inphared_type_ss-RNA']\n",
    "    \n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Filling with zeros\n",
    "        df[col] = df[col].astype(bool)  # Convert to boolean\n",
    "\n",
    "    df['jumbophage_inphared'] = df['genome_length_inphared'].apply(lambda x: x >= 200000)\n",
    "    df['jumbophage_inphared'] = df['jumbophage_inphared'].astype(int)  # Convert True/False to 1/0\n",
    "    \n",
    "\n",
    "    df_length_gc_cds_density = pd.read_csv(f\"{folder}/pharokka_length_gc_cds_density.tsv\", sep=\"\\t\")\n",
    "    df_length_gc_cds_density['contig'] = df_length_gc_cds_density['contig'].str.slice(0,8)\n",
    "    df_length_gc_cds_density\n",
    "\n",
    "    df = pd.merge(df, df_length_gc_cds_density, left_on='id_inphared', right_on='contig', how='outer')\n",
    "    del(df_length_gc_cds_density)\n",
    "\n",
    "    df_cds = pd.read_csv(f\"{folder}/pharokka_cds_functions.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    # Define a dictionary of replacements\n",
    "    replacements = {\n",
    "        \"DNA, RNA and nucleotide metabolism\":\"nucleotide_metabolism\",\n",
    "        \"head and packaging\": \"head_packaging\",\n",
    "        \"moron, auxiliary metabolic gene and host takeover\": \"host_takeover\",\n",
    "        \"transcription regulation\": \"transcription\",\n",
    "        \"unknown function\": \"unkown_function\"\n",
    "    }\n",
    "\n",
    "    # Replace the values using the dictionary\n",
    "    df_cds['Description'] = df_cds['Description'].replace(replacements)\n",
    "\n",
    "    df_cds = df_cds.pivot(index='contig', columns='Description', values='Count').reset_index()\n",
    "    df_cds['contig'] = df_cds['contig'].str.slice(0,8)\n",
    "\n",
    "    df = pd.merge(df, df_cds, left_on='id_inphared', right_on='contig', how='outer')\n",
    "    del(df_cds)\n",
    "\n",
    "\n",
    "    df_frame = pd.read_csv(f\"{folder}/pharokka_cds_final_merged_output.tsv\", sep=\"\\t\",  low_memory=False)\n",
    "\n",
    "    frame_counts = df_frame.groupby('contig')['frame'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "    # Ensure both '+' and '-' columns are present\n",
    "    frame_counts['+'] = frame_counts.get('+', 0)\n",
    "    frame_counts['-'] = frame_counts.get('-', 0)\n",
    "\n",
    "    # Rename columns explicitly\n",
    "    frame_counts = frame_counts.rename(columns={'+': 'frame_positive', '-': 'frame_negative'})\n",
    "\n",
    "    # Reset index if needed\n",
    "    frame_counts = frame_counts.reset_index()\n",
    "    frame_counts = frame_counts.rename_axis(None, axis=1).reset_index()\n",
    "    frame_counts['contig'] = frame_counts['contig'].str.slice(0,8)\n",
    "    df = pd.merge(df, frame_counts, left_on='id_inphared', right_on='contig', how='outer')\n",
    "\n",
    "    df = df.rename(columns={'id_inphared': 'id'})\n",
    "    df['dummy_index'] = 0\n",
    "\n",
    "    # Group by the dummy index and aggregate using 'first'\n",
    "    df = df.groupby('dummy_index').first()\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    columns = ['id','host_inphared','isolation_host_inphared','genome_length_inphared', 'gc_%_inphared', 'cds_number_inphared',\n",
    "       'positive_strand_%_inphared', 'negative_strand_%_inphared',\n",
    "       'coding_capacity_inphared', 'tRNAs_inphared', 'host_inphared',\n",
    "       'isolation_host_inphared', 'molecule_inphared_type_DNA',\n",
    "       'topology_linear', 'jumbophage_inphared', 'topology_circular',\n",
    "       'molecule_inphared_type_ss-DNA', 'molecule_inphared_type_RNA',\n",
    "       'molecule_inphared_type_ss-RNA',  'length', 'gc_perc',\n",
    "       'transl_table', 'cds_coding_density',  'CARD_AMR_Genes',\n",
    "       'CDS', 'CRISPRs', 'VFDB_Virulence_Factors', 'connector',\n",
    "       'head_packaging', 'host_takeover', 'integration and excision', 'lysis',\n",
    "       'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
    "        #'contig_x', 'contig', 'contig_y',\n",
    "       'transcription', 'unkown_function', 'frame_positive',\n",
    "       'frame_negative', 'sequence']\n",
    "    \n",
    "\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staining_feature(staining_df, features_df):\n",
    "    stain = pd.read_csv(staining_df, index_col = 0)\n",
    "    stain = stain[['Accession', 'staining']]\n",
    "    stain = stain.rename(columns={'Accession': 'id'})\n",
    "\n",
    "    features_df = pd.merge(features_df, stain, on='id', how='left')\n",
    "    # columns = ['id','staining','host_inphared','isolation_host_inphared','genome_length_inphared', 'gc_%_inphared', 'cds_number_inphared',\n",
    "    #    'positive_strand_%_inphared', 'negative_strand_%_inphared',\n",
    "    #    'coding_capacity_inphared', 'tRNAs_inphared', 'host_inphared',\n",
    "    #    'isolation_host_inphared', 'molecule_inphared_type_DNA',\n",
    "    #    'topology_linear', 'jumbophage_inphared', 'topology_circular',\n",
    "    #    'molecule_inphared_type_ss-DNA', 'molecule_inphared_type_RNA',\n",
    "    #    'molecule_inphared_type_ss-RNA',  'length', 'gc_perc',\n",
    "    #    'transl_table', 'cds_coding_density',  'CARD_AMR_Genes',\n",
    "    #    'CDS', 'CRISPRs', 'VFDB_Virulence_Factors', 'connector',\n",
    "    #    'head_packaging', 'host_takeover', 'integration and excision', 'lysis',\n",
    "    #    'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
    "    #     #'contig_x', 'contig', 'contig_y',\n",
    "    #    'transcription', 'unkown_function', 'frame_positive',\n",
    "    #    'frame_negative', 'sequence']\n",
    "\n",
    "\n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Accession for folder ../data/interim/pharokka/pharokka_full_output/sequence_18297.fasta.pharokka: from MK761195 to MK972706\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_inphared</th>\n",
       "      <th>isolation_host_inphared</th>\n",
       "      <th>genome_length_inphared</th>\n",
       "      <th>gc_%_inphared</th>\n",
       "      <th>cds_number_inphared</th>\n",
       "      <th>positive_strand_%_inphared</th>\n",
       "      <th>negative_strand_%_inphared</th>\n",
       "      <th>coding_capacity_inphared</th>\n",
       "      <th>tRNAs_inphared</th>\n",
       "      <th>...</th>\n",
       "      <th>other</th>\n",
       "      <th>tRNAs</th>\n",
       "      <th>tail</th>\n",
       "      <th>tmRNAs</th>\n",
       "      <th>transcription</th>\n",
       "      <th>unkown_function</th>\n",
       "      <th>frame_positive</th>\n",
       "      <th>frame_negative</th>\n",
       "      <th>sequence</th>\n",
       "      <th>staining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MK972706</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>43514</td>\n",
       "      <td>49.694</td>\n",
       "      <td>67</td>\n",
       "      <td>68.656716</td>\n",
       "      <td>31.343284</td>\n",
       "      <td>92.108287</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>AGGCCCTGGGGGGCCTCGTACGCAAATTGTCGTACGAAAATAGAGC...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id host_inphared isolation_host_inphared  genome_length_inphared  \\\n",
       "0  MK972706    Salmonella             Unspecified                   43514   \n",
       "\n",
       "   gc_%_inphared  cds_number_inphared  positive_strand_%_inphared  \\\n",
       "0         49.694                   67                   68.656716   \n",
       "\n",
       "   negative_strand_%_inphared  coding_capacity_inphared  tRNAs_inphared  ...  \\\n",
       "0                   31.343284                 92.108287               0  ...   \n",
       "\n",
       "  other tRNAs  tail  tmRNAs  transcription  unkown_function  frame_positive  \\\n",
       "0     1     0     8       0              2               28              22   \n",
       "\n",
       "   frame_negative                                           sequence  staining  \n",
       "0              45  AGGCCCTGGGGGGCCTCGTACGCAAATTGTCGTACGAAAATAGAGC...  positive  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "folder = \"../data/interim/pharokka/pharokka_full_output/sequence_001.fasta.pharokka\"\n",
    "\n",
    "# folder = \"../data/interim/pharokka/pharokka_full_output/sequence_21047.fasta.pharokka\"\n",
    "\n",
    "folder = \"../data/interim/pharokka/pharokka_full_output/sequence_18475.fasta.pharokka\"\n",
    "folder = \"../data/interim/pharokka/pharokka_full_output/sequence_18297.fasta.pharokka\"\n",
    "\n",
    "staining_df = \"../data/interim/gram_staining/staining_assignation.csv\"\n",
    "df = engineer_features(folder)\n",
    "df = staining_feature(staining_df, df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_001.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_002.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_003.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_004.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_005.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_006.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_007.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_008.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_009.fasta.pharokka...\n",
      "Processing ../data/interim/pharokka/pharokka_full_output/sequence_010.fasta.pharokka...\n",
      "(10, 42)\n",
      "Index(['id', 'host_inphared', 'isolation_host_inphared',\n",
      "       'genome_length_inphared', 'gc_%_inphared', 'cds_number_inphared',\n",
      "       'positive_strand_%_inphared', 'negative_strand_%_inphared',\n",
      "       'coding_capacity_inphared', 'tRNAs_inphared', 'host_inphared',\n",
      "       'isolation_host_inphared', 'molecule_inphared_type_DNA',\n",
      "       'topology_linear', 'jumbophage_inphared', 'topology_circular',\n",
      "       'molecule_inphared_type_ss-DNA', 'molecule_inphared_type_RNA',\n",
      "       'molecule_inphared_type_ss-RNA', 'length', 'gc_perc', 'transl_table',\n",
      "       'cds_coding_density', 'CARD_AMR_Genes', 'CDS', 'CRISPRs',\n",
      "       'VFDB_Virulence_Factors', 'connector', 'head_packaging',\n",
      "       'host_takeover', 'integration and excision', 'lysis',\n",
      "       'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
      "       'transcription', 'unkown_function', 'frame_positive', 'frame_negative',\n",
      "       'sequence'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_inphared</th>\n",
       "      <th>isolation_host_inphared</th>\n",
       "      <th>genome_length_inphared</th>\n",
       "      <th>gc_%_inphared</th>\n",
       "      <th>cds_number_inphared</th>\n",
       "      <th>positive_strand_%_inphared</th>\n",
       "      <th>negative_strand_%_inphared</th>\n",
       "      <th>coding_capacity_inphared</th>\n",
       "      <th>tRNAs_inphared</th>\n",
       "      <th>...</th>\n",
       "      <th>other</th>\n",
       "      <th>tRNAs</th>\n",
       "      <th>tail</th>\n",
       "      <th>tmRNAs</th>\n",
       "      <th>transcription</th>\n",
       "      <th>unkown_function</th>\n",
       "      <th>frame_positive</th>\n",
       "      <th>frame_negative</th>\n",
       "      <th>sequence</th>\n",
       "      <th>staining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GU339467</td>\n",
       "      <td>Mycobacterium</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>53332</td>\n",
       "      <td>64.530</td>\n",
       "      <td>90</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>90.416635</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>TGCGGCTGCCCCATCCTGTACGGGTTTCCAAGTCGATCTCGGGGGC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MF417929</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>32618</td>\n",
       "      <td>39.218</td>\n",
       "      <td>42</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>89.416886</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>ATGTTGTCTAGTCCATCATAGGTGCAACGGATATACGAGCATTTTT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MH616963</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>94878</td>\n",
       "      <td>28.507</td>\n",
       "      <td>89</td>\n",
       "      <td>56.179775</td>\n",
       "      <td>43.820225</td>\n",
       "      <td>94.964059</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>ATGTCGAGTATGAGGAATAAGAAACGCTTAATGACGGGGGAGTTCA...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MH552500</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>90023</td>\n",
       "      <td>29.180</td>\n",
       "      <td>86</td>\n",
       "      <td>47.674419</td>\n",
       "      <td>52.325581</td>\n",
       "      <td>92.927363</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>ATGAGTTGTAATCTTTCAATAGACAAGAACATTATTCTTGATAAGA...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BK010471</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>bacterium</td>\n",
       "      <td>97065</td>\n",
       "      <td>29.274</td>\n",
       "      <td>91</td>\n",
       "      <td>50.549451</td>\n",
       "      <td>49.450549</td>\n",
       "      <td>94.458353</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>TAGTAAGAGTGAAAATAATGTATATTGGTGTTTTGGTGAGGCTAGT...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AC171169</td>\n",
       "      <td>Escherichia</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>104373</td>\n",
       "      <td>38.783</td>\n",
       "      <td>146</td>\n",
       "      <td>28.767123</td>\n",
       "      <td>71.232877</td>\n",
       "      <td>89.145660</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>106</td>\n",
       "      <td>GGGTGCTATACAAAAGCGGGGGGCACGAGTCCACCCCGTTTTTCAC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR797314</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>36306</td>\n",
       "      <td>42.059</td>\n",
       "      <td>41</td>\n",
       "      <td>70.731707</td>\n",
       "      <td>29.268293</td>\n",
       "      <td>92.133532</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>GTTCTAATTCATGCAAATCATTAGCTGTTTTATCATCTTTTTCTAG...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MW175890</td>\n",
       "      <td>Dompiswa</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>150892</td>\n",
       "      <td>39.115</td>\n",
       "      <td>272</td>\n",
       "      <td>49.632353</td>\n",
       "      <td>50.367647</td>\n",
       "      <td>91.760332</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>135</td>\n",
       "      <td>137</td>\n",
       "      <td>ATGCCTAAACTAAAACGTGGTCGTGGAAGACCAACAGCCGAAATGC...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KT997847</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>33961</td>\n",
       "      <td>32.384</td>\n",
       "      <td>47</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.555019</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>AATGTATATGTGAGGCCAGATTTTTCCCCCATAGGCGTGGCGTGTA...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP013549</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>41987</td>\n",
       "      <td>51.556</td>\n",
       "      <td>33</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>92.628671</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>CGGGTTCAAGAACTTCTTTCGTTATTGGAACAACGGGATCAAGCAG...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  host_inphared isolation_host_inphared  genome_length_inphared  \\\n",
       "0  GU339467  Mycobacterium             Unspecified                   53332   \n",
       "1  MF417929    Unspecified             Unspecified                   32618   \n",
       "2  MH616963    Unspecified             Unspecified                   94878   \n",
       "3  MH552500    Unspecified             Unspecified                   90023   \n",
       "4  BK010471    Unspecified               bacterium                   97065   \n",
       "5  AC171169    Escherichia             Unspecified                  104373   \n",
       "6  LR797314    Unspecified             Unspecified                   36306   \n",
       "7  MW175890       Dompiswa             Unspecified                  150892   \n",
       "8  KT997847    Unspecified             Unspecified                   33961   \n",
       "9  AP013549    Unspecified             Unspecified                   41987   \n",
       "\n",
       "   gc_%_inphared  cds_number_inphared  positive_strand_%_inphared  \\\n",
       "0         64.530                   90                   40.000000   \n",
       "1         39.218                   42                   16.666667   \n",
       "2         28.507                   89                   56.179775   \n",
       "3         29.180                   86                   47.674419   \n",
       "4         29.274                   91                   50.549451   \n",
       "5         38.783                  146                   28.767123   \n",
       "6         42.059                   41                   70.731707   \n",
       "7         39.115                  272                   49.632353   \n",
       "8         32.384                   47                  100.000000   \n",
       "9         51.556                   33                   66.666667   \n",
       "\n",
       "   negative_strand_%_inphared  coding_capacity_inphared  tRNAs_inphared  ...  \\\n",
       "0                   60.000000                 90.416635               1  ...   \n",
       "1                   83.333333                 89.416886               0  ...   \n",
       "2                   43.820225                 94.964059               2  ...   \n",
       "3                   52.325581                 92.927363               2  ...   \n",
       "4                   49.450549                 94.458353               0  ...   \n",
       "5                   71.232877                 89.145660               6  ...   \n",
       "6                   29.268293                 92.133532               0  ...   \n",
       "7                   50.367647                 91.760332              10  ...   \n",
       "8                    0.000000                 91.555019               1  ...   \n",
       "9                   33.333333                 92.628671               0  ...   \n",
       "\n",
       "  other tRNAs  tail  tmRNAs  transcription  unkown_function  frame_positive  \\\n",
       "0     3     1    13       0              3               44              36   \n",
       "1     1     0    10       0              1               17               7   \n",
       "2     2     3     1       0              0               74              50   \n",
       "3     0     2     0       0              0               72              41   \n",
       "4     2     0     2       0              0               74              47   \n",
       "5     8     7    14       0              3               60              42   \n",
       "6     1     0     3       0              3               22              29   \n",
       "7    14    12    17       0              0              193             135   \n",
       "8     3     1     3       0              0               25              48   \n",
       "9     0     0     3       0              1               18              23   \n",
       "\n",
       "   frame_negative                                           sequence  staining  \n",
       "0              54  TGCGGCTGCCCCATCCTGTACGGGTTTCCAAGTCGATCTCGGGGGC...       NaN  \n",
       "1              35  ATGTTGTCTAGTCCATCATAGGTGCAACGGATATACGAGCATTTTT...       NaN  \n",
       "2              39  ATGTCGAGTATGAGGAATAAGAAACGCTTAATGACGGGGGAGTTCA...       NaN  \n",
       "3              46  ATGAGTTGTAATCTTTCAATAGACAAGAACATTATTCTTGATAAGA...       NaN  \n",
       "4              45  TAGTAAGAGTGAAAATAATGTATATTGGTGTTTTGGTGAGGCTAGT...       NaN  \n",
       "5             106  GGGTGCTATACAAAAGCGGGGGGCACGAGTCCACCCCGTTTTTCAC...       NaN  \n",
       "6              13  GTTCTAATTCATGCAAATCATTAGCTGTTTTATCATCTTTTTCTAG...       NaN  \n",
       "7             137  ATGCCTAAACTAAAACGTGGTCGTGGAAGACCAACAGCCGAAATGC...       NaN  \n",
       "8               0  AATGTATATGTGAGGCCAGATTTTTCCCCCATAGGCGTGGCGTGTA...       NaN  \n",
       "9              11  CGGGTTCAAGAACTTCTTTCGTTATTGGAACAACGGGATCAAGCAG...       NaN  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage 2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "main_folder = '../data/interim/pharokka/pharokka_full_output/'  # Replace with your main folder path\n",
    "dataframes = []  # List to store individual DataFrames\n",
    "max_folders = 10  # Set the maximum number of folders to process\n",
    "processed_folders = 0  # Counter for processed folders\n",
    "\n",
    "# Iterate over each folder in the main folder\n",
    "for folder in os.listdir(main_folder):\n",
    "    # Break the loop if the maximum number of folders has been processed\n",
    "    if processed_folders >= max_folders:\n",
    "        break\n",
    "\n",
    "    folder_path = os.path.join(main_folder, folder)\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Check if \"pharokka.gbk\" file exists in the folder\n",
    "        if \"pharokka.gbk\" in os.listdir(folder_path):\n",
    "            print(f\"Processing {folder_path}...\")\n",
    "            # Pass the full path of \"pharokka.gbk\" to your function\n",
    "            df = engineer_features(os.path.join(folder_path))\n",
    "            dataframes.append(df)\n",
    "            processed_folders += 1\n",
    "        else:\n",
    "            print(f\"Skipped {folder_path}: 'pharokka.gbk' file not found\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(final_df.shape)\n",
    "print(final_df.columns)\n",
    "final_df = staining_feature(staining_df, final_df)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First version of engineer features\n",
    "\n",
    "\n",
    "# Extract the file extension\n",
    "file_ext = os.path.splitext(args.data)[1][1:] \n",
    "\n",
    "fasta_extensions = [\"fasta\", \"fas\", \"fa\", \"fna\", \"ffn\", \"faa\", \"mpfa\", \"frn\"]\n",
    "genbank_extensions = [\"gb\", \"gbk\"]\n",
    "\n",
    "# Processing the input data --------\n",
    "\n",
    "#TODO: pharokka\n",
    "# Process as a FASTA file\n",
    "if file_ext in fasta_extensions:\n",
    "    pass  # Replace PHAROKKA\n",
    "\n",
    " # Process as a GenBank file\n",
    "elif file_ext in genbank_extensions:\n",
    "    model_data = engineer_features(args.data)\n",
    "\n",
    "else:\n",
    "    supported_formats = ', '.join(fasta_extensions + genbank_extensions)\n",
    "    print(f\"Unsupported file format: {file_ext}. Supported formats are: {supported_formats}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "features = ['genome_length', 'jumbophage', 'gc_%',\n",
    "       'trna_count', 'cds_number', 'coding_capacity', 'positive_strand_%',\n",
    "       'negative_strand_%', 'molecule_type_ss-DNA', 'molecule_type_DNA',\n",
    "       'molecule_type_RNA', 'molecule_type_ss-RNA', 'topology_circular','topology_linear']\n",
    "model_data = model_data.set_index(model_data.columns[0])\n",
    "model_data = model_data[features]\n",
    "\n",
    "# Making the prediction -----\n",
    "\n",
    "# Load the model using the provided path\n",
    "rf = pickle.load(open(args.model, \"rb\"))\n",
    "\n",
    "# Predictions\n",
    "new_data_pred = rf.predict(model_data)\n",
    "\n",
    "# Get the probabilities for the predicted class for each instance\n",
    "probas = rf.predict_proba(model_data)\n",
    "predicted_indices = np.argmax(probas, axis=1)  # Get index of max proba for each sample\n",
    "new_data_pred_proba = [probas[i][predicted_indices[i]] for i in range(len(predicted_indices))]\n",
    "\n",
    "# Prepare the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'id': model_data.index,\n",
    "    'prediction': new_data_pred,\n",
    "    'prediction_probability': new_data_pred_proba\n",
    "})\n",
    "\n",
    "# Uncomment the following line if you want to save the output to a CSV\n",
    "output_df.to_csv(args.output, index=False)\n",
    "\n",
    "print()\n",
    "print(f\"The output has been saved in {args.output}. The first 5 entries are: \")\n",
    "print(output_df.head())\n",
    "\n",
    "# python -m src.models.predict_model -d data/interim/genbank_engineering/50_sequences.gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def unix_call(command, environment=None):\n",
    "    if environment:  # If the environment is specified, prepend with 'conda run -n env_name'\n",
    "        command = f\"conda run -n {environment} {command}\"\n",
    "    subprocess.run(command, shell=True, check=True)  # Use 'shell=True' to interpret the command as a shell command\n",
    "\n",
    "def process_fasta(file_path, output_dir, database_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Processing FASTA file: {file_path}\")\n",
    "\n",
    "    # Run Pharokka using the pharokkaENV environment\n",
    "    unix_call(f'pharokka.py -i {file_path} -o {output_dir} -f -m -t 16 -d {database_dir}', environment='pharokkaENV')\n",
    "\n",
    "    \n",
    "# Check if the input data path is a directory or a file\n",
    "if os.path.isdir(args.data):\n",
    "    # The input is a directory; process all relevant files within\n",
    "    print(f\"Processing Pharokka output in directory: {args.data}\")\n",
    "    model_data = engineer_features(args.data)\n",
    "\n",
    "elif os.path.isfile(args.data):\n",
    "    # The input is a file; check if it's a FASTA file\n",
    "    file_ext = os.path.splitext(args.data)[1][1:].lower()\n",
    "    if file_ext in fasta_extensions:\n",
    "        output_dir = \"/mnt/c/Users/Alvaro/Desktop/pharokka_output/\"\n",
    "        database_dir = \"/mnt/c/Users/Alvaro/Desktop/pharokka_database/\"\n",
    "        # TODO: add argument for output directory, databse directory and threads for pharokka\n",
    "        process_fasta(args.data, output_dir, database_dir)  # Call your processing function\n",
    "\n",
    "        # The input is a directory; process all relevant files within\n",
    "        print(f\"Processing Pharokka output in directory: {output_dir}\")\n",
    "        model_data = engineer_features(output_dir)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_ext}. Supported FASTA formats are: {', '.join(fasta_extensions)}\")\n",
    "        exit(1)\n",
    "\n",
    "else:\n",
    "    print(f\"The provided data path does not exist: {args.data}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "features = ['genome_length_inphared', 'gc_%_inphared',\n",
    "        'cds_number_inphared', 'positive_strand_%_inphared',\n",
    "        'negative_strand_%_inphared', 'coding_capacity_inphared',\n",
    "        'molecule_type_inphared_DNA', 'topology_inphared_linear',\n",
    "        'jumbophage_inphared', 'topology_linear_inphared',\n",
    "        'topology_circular_inphared', 'molecule_inphared_type_ss-DNA',\n",
    "        'molecule_inphared_type_DNA', 'molecule_inphared_type_RNA',\n",
    "        'molecule_inphared_type_ss-RNA', 'length', 'gc_perc',\n",
    "        'transl_table', 'cds_coding_density', 'CARD_AMR_Genes',\n",
    "        'CDS', 'CRISPRs', 'VFDB_Virulence_Factors', 'connector',\n",
    "        'head_packaging', 'host_takeover', 'integration and excision', 'lysis',\n",
    "        'nucleotide_metabolism', 'other', 'tRNAs', 'tail', 'tmRNAs',\n",
    "        'transcription', 'unkown_function', 'frame_negative',\n",
    "        'frame_positive', 'sequence_inphared', 'reverse_complement_inphared']\n",
    "\n",
    "model_data = model_data.set_index(model_data.columns[0])\n",
    "\n",
    "\n",
    "model_data = model_data[features]\n",
    "\n",
    "\n",
    "# Making the prediction -----\n",
    "\n",
    "# Load the model using the provided path\n",
    "rf = pickle.load(open(args.model, \"rb\"))\n",
    "\n",
    "# Predictions\n",
    "new_data_pred = rf.predict(model_data)\n",
    "\n",
    "# Get the probabilities for the predicted class for each instance\n",
    "probas = rf.predict_proba(model_data)\n",
    "predicted_indices = np.argmax(probas, axis=1)  # Get index of max proba for each sample\n",
    "new_data_pred_proba = [probas[i][predicted_indices[i]] for i in range(len(predicted_indices))]\n",
    "\n",
    "# Prepare the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'id': model_data.index,\n",
    "    'prediction': new_data_pred,\n",
    "    'prediction_probability': new_data_pred_proba\n",
    "})\n",
    "\n",
    "# Uncomment the following line if you want to save the output to a CSV\n",
    "output_df.to_csv(args.output, index=False)\n",
    "\n",
    "print()\n",
    "print(f\"The output has been saved in {args.output}. The first 5 entries are: \")\n",
    "print(output_df.head())\n",
    "\n",
    "# python -m src.models.predict_model -d data/interim/genbank_engineering/50_sequences.gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
